<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="EssayOne.css" />
    <title>Essay Two: Mitigating the Risk of Extinction From AI.</title>
  </head>
  <body>
    <div class="essay">
      <div class="date">26 June 2023</div>
      <h1>Essay Two: The Impact Of Algorithmic Culture And AI On The Internet Using “The World In WWW And Digital Inequalities” As A Theoretical Framework.</h1>

      <h2>INTRODUCTION</h2>
      <p class="paragraph">
        The world as we know it is changing rapidly and is characterized by industrialization.  Although arguable, economic eras are classified on three general industrial revolutions i.e. first industrial revolution (1760 - 1850), second industrial revolution (1870 – 1970) and third industrial revolution (from 1960’s) (Sutherland, 2020).  Rapid transformation in the world of work however has predicted that we are entering a fourth revolution of “3D - printing, artificial intelligence (AI), big data, industrial internet and auto cannibalization of business models” (Sutherland, 2020). 
        This form of industrialization is underpinned by algorithmic culture that utilize AI systems to create text, images, videos which are “becoming difficult to distinguish from human – created content” (Centre for AI Safety, 2023).  In addition, the CAIS, argue that this rapid transformation of AI systems in becoming efficient, that too with human interaction, are becoming increasingly self-sufficient to an extent that they pose “catastrophic or existential risks”.</p>



      <h2>DEFINING AI RISK</h2>
      <p class="paragraph">
        In formulating their narrative, CAIS have crafted a statement that “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war” (Centre for AI Safety, 2023).  This statement has been signed by 350 signatories, two of which are “Hinton and Yoshua Bengio winners of the Nobel prize in computing and fathers of the AI revolution” (Colome, 2023) and is extremely important within the context of the developing AI technologies.  The rapid pace at which these technologies are being integrated into our daily lives, brings about a number of concerns that can have catastrophic consequences such as weaponization, where AI could be repurposed destructively, misinformation where content can be used to influence particular narratives, proxy gaming which has the potential to influence preferences, enfeeblement where important activities are relegated to machines thus making humans highly reliant on machines to do their work, value lock-in which creates selective and oppressive systems, emergent goals where people have limited control over machines, deception where information is collected can undermine human imperatives and finally power-seeking behaviour where AI acquires sufficient power and make them dangerous (Centre for AI Safety, 2023).  

Jordi Pèrez Colomè in his article highlights the alarming increase of experts who have requested that AI be halted, observed and controlled due to its risks.  Sam Altman, the CEO of OpenAI, responsible for the creation of ChatGPT affirmed before Congress that things can turn out badly.  Contrary to these views, one of the three creators of AI technology: Yann LeCun did not acknowledge the risk due to its infancy.  Altman was also of the opinion that there has to be some sort of transcendence to truly understand if these risks are indeed inherent (Colome, 2023).  

In general, AI risk seems to be a contentious issue with some calling it a hype while others calling it hypocrisy for not acknowledging it sooner.  The pace with which AI is progressing may bring unforeseen dangers if not managed.

      </p>

      <h2>CURRENT MANIFESTATIONS WITHIN AN ALGORITHMIC CULTURE </h2>
      <p class="paragraph">
        Algorithmic culture is fundamentally changing our systems, views and our lives as they regulate the power dynamics of information within a global context.  Graham, De Sabbata and Zook (2015), in their theoretical study, focused on three key areas: geographies of access and enablement, geographies of participation and geographies of representation.  Within the “geographies of access and enablement” perspective, the study highlighted, internet access as a key concern with significant displacement between internet users by country and internet affordability and concluded that “despite the uneven geographies” about 3 billion users had some type of access (Graham et al., 2015).  

        In the second area of study “geographies of participation”, Graham, De Sabbata and Zook (2015), selected three areas for data collection: domain names, Github users and Wikipedia edits.  This area showed a very distorted scenario where large internet populations did not translate into significant domain registrations and where large differences in access are more likely to be producers of digital content.
        
        In the final area of study, “geographies of representation”, Graham, De Sabbata and Zook, utilised digital representations to show patterns of unevenness throughout different platforms.  Two extremes surfaced: some areas of the world were significantly over-represented while in comparison, the rest of the world, were under-represented.
        
        These types of inequalities are also predominant in the new age of AI.  Christoph Lutz (2019) claims that the increasing dependence on AI and big data in society have the potential to further exacerbate the existing inequalities and create new forms of inequality.  Digital inequality outlines the unequal distribution of access, skills and resources linked to digital technologies which can result in difference in opportunities and outcomes for individuals and groups.  According to Lutz (2019), access to AI technology and effectively using big data is unevenly distributed and favors those endowed with resources, power and privilege.  Central to this theory are issues of imbalances in mobile internet connectivity, digital literacy and participation in the digital economy due to skills and discriminatory practices that are found entrenched in AI algorithms.  These have severe consequences to society and need to be addressed for a more equitable and inclusive digital future.
        
        Massimo Ragneda and Maria Laura Ruiu also reciprocate on the three levels of division and social capital.  The authors propose that social capital which refers to networks, relationships and resources that individuals have access to, through their social networks significantly shapes digital inequalities.  The first level is the “access divide” which refers to unequal access to digital technologies such as internet connectivity and devices which is influenced by socioeconomic factors, geographic location and infrastructure restrictions.  The second level highlights the “inequalities in terms of motivation, skills and purpose of use” and the third level highlights disparities in “social/cultural/economic/personal/political” divide resulting in benefits from their online experience.  Addressing these divides may not only improve access and skills but also requires leveraging social capital, building networks and promoting digital inclusion to empower communities (Ragnedda & Ruiu, 2017).  
        
      </p>

      <h2>RESULTANT ASSUMPTIONS AND ANALYSIS</h2>
      <p class="paragraph">
        Drawing from the theory provided by Graham, De Sabbata and Zook, on the “geographies of access and enablement” (Graham et al., 2015) the displacement of internet access displays severe constraints to users in countries that have uneven geographies.  With the pace of increasing AI and this being entrenched in every aspect of life, the risk of misinformation can also increase.  The apparent displacement between geographies can potentially create opportunities for specific narratives to be developed and used to influence a particular group.  An example of this can be likened to colonialization where the basis of annexation of a particular land was premised on dividing the people.  If a particular narrative can be created and used to influence nations that have limited users, this narrative can be the theme which is thrust into the political landscape, creating instability and opportunist behavior in the country which may result in political, environmental and social and technical challenges.

The same may be perceived of “geographies of participation” (Graham et al., 2015), where producers of content may have unparalleled skills compared to the rest of the world who are semi or unskilled.  This type of elitist behavior may be carried forward as a sense of enfeeblement through machine learning where the dependence on AI becomes so significant that participation is delegated to technology.  With machines doing most of the work, there is a huge power displacement where the reliance on AI becomes unparalleled and where AI goals eventually supersede the goals of humans. 

Examples of these can be seen in certain retail stores where the work of cashiers have been automated or in vehicle manufacturing where complex work is now delegated to robots.  AI technology such as ChatGPT for example has the potential of eradicating unique creative skills as more users adopt the AI technology to do work.  Enfeeblement may have a deeper temperament of pilfering skills through delegation.  AI systems that are tasked to do specific work in the spirit that machines are better at routine tasks may turn out to be rather a transfer of weaker skills to users.  Users will learn basic user skills for AI manipulation in place of creative skills left to technology.

The patterns of unevenness prevalent in “geographies of representation”, manifest through usage.  The disparities surface when there is a limited use of particular platforms where “contemporary semantic web services” are used for example social media (Graham et al., 2015).  Social media has a significant investment in algorithmic culture.  The expansion of social media has necessitated increased interaction, (Suárez-Gonzalo et al., 2019).  Chatbots based on “data analytics and machine learning” have been developed to “interact with users on social networks”.  Accordingly, this type of technology is based on algorithmic modelling for functional responses, unlike the personal interactions that people are used to.  The personal interface between people relying on human emotions, is therefore lost. 

The intricacy of the algorithmic responses and machine learning, opens these technologies “to problematic concepts such as agency, accountability or the attribution of responsibility” within the paradigm of “algorithmic culture” (Hallinan & Striphas, 2016).  A typical case in point is the “Tays failure”, a twitter chatbot launched by Microsoft in 2016.  After 24 hours of interaction with Twitter users, “the bot messages became racist, homophobic and sexist hate speech” (Suárez-Gonzalo et al., 2019).  

Delegating responsibility to algorithms that are not entirely autonomous entities, creates a number of complexities.  When a bot fails, (Suárez-Gonzalo et al., 2019) claim that the responsibility for this failure may lie with the designers, software engineers and organizations that they represent and may even go as far as societal, cultural and organizational contexts by virtue of the range and scope of algorithmic decision-making. One can easily discern the level of complexity “geographies of representation” attract for example legal, commercial and financial risks.  In contrast, the lack of representation may mean that more tasks will be delegated to AI technologies, centralized in geographies that have more power users.  These power users for example will have the range and scope to influence narratives and create dependency.  What we see is a shift of power back to developed countries where the ever increasing gap between them and developing countries widens more and more.

The theoretical considerations made by (Lutz, 2019; Ragnedda & Ruiu, 2017) highlights similar trends: three levels of digital division and the impact of social capital on these divides respectively.  To reiterate, similar themes of access, skills, resources and social exclusivity emerge, and AI seems to be in the middle of it dictating the terms of engagement.  AI is set to become ubiquitous technology were the power dynamics become centralized and where absolute power corrupts absolutely. 

      </p>

      <h2>CONCLUSION</h2>
      <p class="paragraph">
        The impact of algorithmic culture and AI in the digital world will have a profound effect on the way things are done in the future.  The impact of technology is increasing at an alarming rate with more and more reliance being placed on systems that can learn fairly quickly.  The disparity in the current landscape displays a different set of dynamics where technology can dictate the terms and conditions of the social, political, environmental and technological spheres that have the ability to shape specific narratives that may generate risks that can undermine the natural order of things.  These risks need to be acknowledged and mitigated.


      </p>

      <h3 class="title">SOURCES CONSULTED</h3>
    <p class="space">
        Centre for AI Safety. (2023). Statement on AI Risk.
    </p>

    <p class="space">
        Colome, J. P. (2023, June 4). Why are the people who pushed for artificial intelligence now signing so many doomsday manifestos? Science & Tech. 
    </p class="space">

    <p class="space">
        Colomé, P (2023). Science and Tech: Why are the people who pushed for Artificial Intelligence now signing so many doomsday manifesto’s? Available: https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html
        Accessed: 21 June 2023
        
    </p>

    <p class="space">
        Graham, M., De Sabbata, S., & Zook, M. A. (2015). Towards a study of information geographies: (im)mutable augmentations and a mapping of the geographies of information. Geo: Geography and Environment, 2(1), 88–105. https://doi.org/10.1002/geo2.8
    </p>

    <p class="space">
        Hallinan, B., & Striphas, T. (2016). Recommended for you- The Netflix Prize and the production of algorithmic culture. New Media and Society, 18(1), 117–137. https://doi.org/10.1177:1461444814538646
    </p>

    <p class="space">
        Lutz, C. (2019). Digital inequalities in the age of artificial intelligence and big data. Human Behavior and Emerging Technologies, 1(2), 141–148. https://doi.org/10.1002/hbe2.140
    </p>

    <p class="space">
        Ragnedda, M., & Ruiu, M. L. (2017). Social capital and the three levels of digital divide. . In Theorizing Digital Divides (pp. 21–34). Routledge.
    </p>

    <p class="space">
        Suárez-Gonzalo, S., Mas-Manchón, L., & Guerrero-Solé, F. (2019). Tay is you. The attribution of responsibility in the algorithmic culture. In Observatorio (OBS*) Journal. http://obs.obercom.pt.


    </p>

    <p class="space">
        Sutherland, E. (2020). The Fourth Industrial Revolution–The Case of South Africa. Politikon, 47(2), 233–252. https://doi.org/10.1080/02589346.2019.1696003
    </p>

    

    </div>

 <!--TO THE TOP BUTTON-->

 <button onclick="topFunction()" id="myBtn" title="Back to Top">
    Back to Top
  </button>

  <script type="text/javascript" src="EssayOT.js"></script>

  <a href="essay.html">Back to Essay Menu.</a>

  </body>
</html>
